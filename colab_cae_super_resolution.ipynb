{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Super-résolution d'image avec un CAE (Convolutional Autoencoder)\n",
        "\n",
        "Ce notebook **Google Colab** montre une pipeline complète en Python:\n",
        "\n",
        "1. Charger des images haute qualité (CIFAR-10).\n",
        "2. Dégrader les images pour générer des entrées basse qualité.\n",
        "3. Entraîner un **CAE** pour reconstruire une image de meilleure qualité.\n",
        "4. Visualiser les résultats (entrée LQ vs sortie du CAE vs cible HQ)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports et configuration\n",
        "\n",
        "> Sur Colab, TensorFlow est généralement déjà installé."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Charger les données (CIFAR-10)\n",
        "\n",
        "Pour un notebook rapide sur Colab, CIFAR-10 est pratique (images 32x32).\n",
        "L'image \"haute qualité\" cible sera l'image originale, et l'image basse qualité sera une version dégradée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "(x_train, _), (x_test, _) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "print(\"Train:\", x_train.shape, x_train.dtype)\n",
        "print(\"Test:\", x_test.shape, x_test.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Générer des images basse qualité (pipeline de dégradation)\n",
        "\n",
        "On simule une image basse qualité via:\n",
        "- réduction de résolution (32→16),\n",
        "- ré-agrandissement (16→32),\n",
        "- ajout d'un léger bruit gaussien."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def degrade_images(images, downscale_size=16, noise_std=0.03):\n",
        "    # Downsample puis upsample (perte d'information)\n",
        "    low = tf.image.resize(images, [downscale_size, downscale_size], method=\"area\")\n",
        "    low = tf.image.resize(low, [32, 32], method=\"bicubic\")\n",
        "\n",
        "    # Bruit gaussien\n",
        "    noise = tf.random.normal(tf.shape(low), mean=0.0, stddev=noise_std, dtype=low.dtype)\n",
        "    low = tf.clip_by_value(low + noise, 0.0, 1.0)\n",
        "    return low\n",
        "\n",
        "x_train_lq = degrade_images(x_train)\n",
        "x_test_lq = degrade_images(x_test)\n",
        "\n",
        "print(\"Train LQ:\", x_train_lq.shape)\n",
        "print(\"Test LQ:\", x_test_lq.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Construire le modèle CAE\n",
        "\n",
        "Le modèle encode d'abord l'image (compression), puis la décode (reconstruction)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def build_cae(input_shape=(32, 32, 3)):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # Encodeur\n",
        "    x = tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D(2)(x)  # 16x16\n",
        "    x = tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.MaxPooling2D(2)(x)  # 8x8\n",
        "\n",
        "    # Bottleneck\n",
        "    x = tf.keras.layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "    # Décodeur\n",
        "    x = tf.keras.layers.Conv2DTranspose(128, 3, strides=2, padding=\"same\", activation=\"relu\")(x)  # 16x16\n",
        "    x = tf.keras.layers.Conv2DTranspose(64, 3, strides=2, padding=\"same\", activation=\"relu\")(x)   # 32x32\n",
        "    outputs = tf.keras.layers.Conv2D(3, 3, padding=\"same\", activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"cae_super_resolution\")\n",
        "    return model\n",
        "\n",
        "model = build_cae()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=\"mae\", metrics=[\"mse\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Entraîner le CAE\n",
        "\n",
        "Pour une démo Colab rapide, on peut sous-échantillonner le dataset.\n",
        "Tu peux augmenter `subset_size` et `epochs` pour une meilleure qualité."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "subset_size = 20000\n",
        "x_train_lq_sub = x_train_lq[:subset_size]\n",
        "x_train_hq_sub = x_train[:subset_size]\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_lq_sub,\n",
        "    x_train_hq_sub,\n",
        "    validation_split=0.1,\n",
        "    epochs=12,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Évaluer et visualiser les résultats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "test_loss, test_mse = model.evaluate(x_test_lq, x_test, verbose=0)\n",
        "print(f\"Test MAE: {test_loss:.4f} | Test MSE: {test_mse:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def show_results(low_quality, predictions, targets, n=6):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(n):\n",
        "        # Entrée basse qualité\n",
        "        ax = plt.subplot(3, n, i + 1)\n",
        "        plt.imshow(low_quality[i])\n",
        "        plt.title(\"Entrée LQ\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Sortie CAE\n",
        "        ax = plt.subplot(3, n, i + 1 + n)\n",
        "        plt.imshow(predictions[i])\n",
        "        plt.title(\"Sortie CAE\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        # Cible haute qualité\n",
        "        ax = plt.subplot(3, n, i + 1 + 2*n)\n",
        "        plt.imshow(targets[i])\n",
        "        plt.title(\"Cible HQ\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "num_show = 6\n",
        "preds = model.predict(x_test_lq[:num_show])\n",
        "show_results(x_test_lq[:num_show], preds, x_test[:num_show], n=num_show)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) (Optionnel) Sauvegarder le modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "save_path = \"cae_super_resolution.keras\"\n",
        "model.save(save_path)\n",
        "print(\"Modèle sauvegardé dans:\", save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Idées d'amélioration\n",
        "\n",
        "- Ajouter des **skip connections** (style U-Net).\n",
        "- Utiliser une perte perceptuelle (VGG) en plus de MAE/MSE.\n",
        "- Entraîner sur un dataset HD (DIV2K, Flickr2K, etc.).\n",
        "- Tester différentes dégradations (flou, compression JPEG, bruit plus fort)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}